# Linear Model
![화면 캡처 2022-01-09 150801](https://user-images.githubusercontent.com/44192730/148671309-eace8d88-7ff4-47eb-8063-6906709ace83.png)
- 가장 간단한 형태의 모델로서 다른 모델들의 기본이 된다.
- 선형 모델은 파라미터가 선형식으로 표현되는 모델을 의미한다.. 따라서 파라미터를 추정하거나 모델을 해석하기가 비선형 모델에 비해 쉽다는 특징이 있다. 하지만 표현 가능한 모델의 가짓 수(파라미터의 결합 형태)가 한정되어 있기 때문에 유연성이 떨어지기 때문에 복잡한 패턴을 갖고 있는 데이터에는 정확한 모델이 불가능할 수 있다.
- output variable의 형태에 따라서 Regression / Classification 2가지로 나뉜다.
    - Regression: output variable이 연속적인 형태를 보이고 모델의 input으로부터 output variable을 직접 예측하는 경우.
    - Classification: output variable이 클래스 레이블로 주어지며 decision boundary를 linear model을 가지고 찾아 분류 문제를 해결하는 경우.
---
## 1) Linear Regression
![화면 캡처 2022-01-09 150826](https://user-images.githubusercontent.com/44192730/148671322-87ee70ba-3daa-4de9-b490-e2b6d3b3d4e9.png)
- [선형 회귀](https://ko.wikipedia.org/wiki/%EC%84%A0%ED%98%95_%ED%9A%8C%EA%B7%80)는 종속변수 y와 한 개 이상의 독립 변수 x의 선형 상관관계를 모델링하는 회귀분석 기법이다.
- 손실 함수로는 MSE를 주로 사용하는데 예측값과 실제값의 오차의 제곱의 평균을 구하는 방법으로 MSE값이 낮을 수록 정답에 가깝다고 해석할 수 있다.

![화면 캡처 2022-01-09 150715](https://user-images.githubusercontent.com/44192730/148671296-42a17c52-8d2d-4222-91d4-970f9632c6cc.png)
- 현실에서 주로 마주하는 문제들은 함수들이 closed-form 형태가 아니고 더 복잡한 형태이고 이때는 미분계수와 그 근을 계산하기 어려워 미분계수가 0인 지점(기울기가 0인 지점)을 찾기가 어려울 수 있다.
- 이럴때 효과적으로 함수의 최소값을 구하기 위해 gradient descent 방법이 사용된다.
- 쉽게 설명하면 gradient descent는 함수의 기울기를 이용해 x의 값을 어디로 옮겼을 때 함수가 최소값이 되는지 알아보는 방법이다. 기울기가 양수면 x값이 커질때 함수값이 커지고 반대로 기울기가 음수면 x값이 커질때 함수값이 작아진다.

![화면 캡처 2022-01-09 150935](https://user-images.githubusercontent.com/44192730/148671345-7a5f3d8b-531d-48ec-a524-dd00a01bda7d.png)
- 위 그림에서 보는 것과 같이 함수의 기울기를 구하고 결사의 절대값이 낮은 쪽으로 이동한다.

![화면 캡처 2022-01-09 151024](https://user-images.githubusercontent.com/44192730/148671354-2449cdf0-fb72-42da-a3ed-a02fc27ee629.png)

---
## 2) Linear Classification
![화면 캡처 2022-01-09 151226](https://user-images.githubusercontent.com/44192730/148671412-cd1d9f3c-f896-44af-b008-453cb1fbf7d3.png)
- output variable이 class label 형태로 주어진 문제로 위 그래프의 파랑색 선과 같은 linear decision boundary를 찾는 문제이다.
- 위 예시의 경우에는 클래스 분류를 결과 값의 부호를 기준으로 나누었다.

![화면 캡처 2022-01-09 151124](https://user-images.githubusercontent.com/44192730/148671377-49f29c76-772d-47f0-8e57-97c9c2c99977.png)
- 클래스 분류를 위해 threshold 함수를 사용해서 특정 문턱값을 기준으로 결과값을 0, 1로 나눌 수 있다.
- 이를 perceptron이라고도 한다. (perceptron은 인간의 뇌의 뉴런의 동작 방식 즉, 자극이 있으면 1 자극이 없으면 0으로 신호를 흘려보내는 특징을 모델링 한 것이다.)
- 모델은 모든 x값들에 대해서 perceptron learning rule에 의한 계산을 진행하여 decision boundary를 찾는다. 이때 예측값과 실제값이 다르면 계속해서 weight 없데이트가 진행되기 때문에 완전히 linearly separable(선형 분류 가능한) 문제에만 사용하게 된다.

---
## 3) Logistic Regression
![화면 캡처 2022-01-09 151447](https://user-images.githubusercontent.com/44192730/148671463-43448586-e134-4ab1-9592-70555237f37a.png)
- logistic function을 이용해서 입력값이 각 레이블에 속할 확률을 계산하여 분류를 하는 방법이다.
- soft threshold 또는 sigmoid라고도 불린다.
- 손실 함수로 MSE를 사용하지 않는 이유는 logistic 함수로 인해 비선형성이 생기기 때문이다. 따라서 log loss 함수를 대신 손실 함수로 사용하게 된다.

---
![화면 캡처 2022-01-09 151526](https://user-images.githubusercontent.com/44192730/148671478-4dd5e0fc-acd4-4650-8c96-9815f3884ec1.png)
- 선형모델을 기본으로하는 모델이다.
- 하나의 뉴런에서 입력값을 linear model을 이용해서 값을 계산하고 threshold나 logistic function과 같은 activation 함수를 통해서 계산한 값을 output으로 반환한다.
- 이런 뉴런들을 여러개의 층으로 쌓아 많든 모델이 바로 Deep Learning의 가장 기본이 되는 모델인 Neural Network이다.
