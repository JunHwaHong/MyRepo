# Machine Learning Basics

![화면 캡처 2022-01-09 141119](https://user-images.githubusercontent.com/44192730/148670333-2f707abd-4409-4c7b-a8fc-73b03cea88d2.png)
- 머신러닝의 단계
    1. training / learning: 데이터를 모델에 학습하는 단계
    2. test: 테스트 데이터 세트를 활용해서 모델 성능을 평가하는 단계
- 데이터셋 구성
    - training: 모델 학습
    - validation: 모델 선택 (파라미터 최적화 등)
    - test: 모델 성능 측정
    - 데이터셋이 몇 만개 정도일때 6:2:2로 구성하며 100만개 이상의 큰 데이터셋에 대해서는 98:1:1로 구성한다.
    
![화면 캡처 2022-01-09 141231](https://user-images.githubusercontent.com/44192730/148670341-0b461e0f-11d2-404c-a7e5-1cd261650600.png)
- 데이터가 충분치 않은 경우에는 데이터의 구성에 따라서 모델의 성능이 바뀔 수 있다.
- 이러한 문제를 방지하기 위한 방법 중 [k-fold cross validation](https://scikit-learn.org/stable/modules/cross_validation.html)이 있다.
- k-fold cross validation
    1. 데이터를 k개의 부분 집합으로 나눈다.
    2. k번의 학습을 진행하는데, 1개의 부분 집합을 test 셋으로 나머지를 training 셋으로 사용한다.
    3. 평균 test 셋 에러를 계산한다.

- 모델의 평가를 위해서 [Loss function](https://en.wikipedia.org/wiki/Loss_function)을 사용하고 Task에 따라서 다른 종류를 사용한다.

![화면 캡처 2022-01-09 141314](https://user-images.githubusercontent.com/44192730/148670357-5afb5b8d-dece-4118-aa9e-d09912d7cfa4.png)
- 머신러닝의 궁극적인 목표는 새로운(unseen) 데이터에 대한 예측 성능을 향상시키는 것이다.
- 이를 error 관점에서 얘기할 때 Generalization error를 0으로 만드는 것이라 할 수 있다. 하지만 실제로 Generalizaition error를 측정하는 것이 쉽지 않기 때문에 우리는 train 데이터에 대한 error를 줄이면서 이와 동시에 train error와 test error가 같아지게하는 2개의 목표를 가지게 된다.
    - Object 1: $E_{train} \simeq 0$
        - training 데이터로 모델을 학습
        - optimization과 complex model이 필요로 한다.
        - 모델이 제대로 학습을 하지 못해 train error가 0보다 클 경우 underfitting되었다고 하며 bias가 높다고 할 수 있다.
    - Object 2: $E_{test} \simeq E_{train}$
        - test error와 train error를 같게 하기 위해서 모델의 복잡도를 줄이는 regularization 방법들이 필요로 한다.
        - 더 많은 train 데이터를 추가하기도 한다.
        - 두 error의 차이가 클 경우 overfitting되었다고 하며 variance가 크다고 할 수 있다.

![화면 캡처 2022-01-09 141353](https://user-images.githubusercontent.com/44192730/148670375-8906495c-c7f8-4f0f-a57e-a7356bd5900c.png)
- 모델의 복잡도는 capacity로 표현한다.
- capacity가 크면 모델이 더 다양한 함수에 적용 가능하며 overfitting될 가능성이 크고 반대로 capacity가 작으면 모델이 단순한 함수에 피팅되기 때문에 underfitting될 가능성이 크다.
- 모델을 잘 고르는 방법은 쉽게 말하면 "**데이터에 가장 잘 부합하는 모델에서 가장 단순한 모델을 고르는 것**"이라는 Occam's razor라는 어구가 있다.

![화면 캡처 2022-01-09 141427](https://user-images.githubusercontent.com/44192730/148670388-e0177762-ae63-405a-bbfa-9a27e7e25d4c.png)
- 모델의 capacity에 대한 딜레마는 머신러닝의 가장 큰 딜레마라고 할 수 있다.
- capacity를 키우면 generalization이 떨어지게 되고 capacity를 줄이게 되면 approximation error 모델의 성능이 떨어지게 된다. 따라서 이 tradeoff를 잘 해결하는 것이 머신러닝의 핵심이라고 할 수 있다.
- 해결방법에는 여러가지가 있다.
    - optimization:
    - regularization
    - 특히 딥러닝에서는 gradient decent와 같은 좋은 optimization 방법과 drop-out과 같은 좋은 regularization 방법이 있어 이러한 부분에서 큰 성능 향상을 이뤄낼 수 있다.


